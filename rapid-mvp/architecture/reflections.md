# A3 Reflections: How A2 CUJ + Week 2 Feedback Drove Architectural Maturity

In A2, our MVP was functionally correct—randomization avoided repeats, team metadata was displayed, and the dual-phase timer transitioned. A2’s CUJ audit and Week 2 peer feedback surfaced a gap between *correctness* and *usability*: small frictions and missing tools that will be handy in real classroom settings.

That insight directly influenced our A3 architecture decisions. Firstly, it reframed our understanding of the need for production-grade persistence. In A2, we treated persistence as optional; after the CUJ, we recognized that instructors need continuity across refreshes, redeploys, and repeated sessions. This pushed us to formalize a true data layer: a Railway backend with persistent storage accessed through Prisma mounted through Railway volume. Even though the project scale is small, we architected for reliability. State must survive redeploys, and data must remain accessible after class. This was our first “architecture upgrade” driven by CUJ thinking: treating persistence as a system guarantee, not a local convenience.

Secondly, CUJ findings changed what we persist and why. In A2, everything implicitly assumed a single user in a local environment. In A3, we added a dedicated login flow with JWT-based authentication to store data safely and predictably per instructor. The audit also showed that instructors are not only managing selection and time—they are producing outcomes (feedback, observations, and timing constraints) that they want to reference later. That requirement drove a deliberate expansion of the data model and API boundaries. We added an **Instructor Notes System** that persists per-team notes and automatically loads them when a team is selected, minimizing context switches during the live session. We also persisted the **presentation and Q&A timing information** and integrated both notes and timing into **CSV exports**, making the data layer useful beyond the moment of presentation. This is an architectural decision as much as a UI feature: it required defining stable persistence, durable export endpoints, and a data plane that can reconstruct session context after the fact.

Lastly, Week 2 feedback and the CUJ lowlights shaped our application/presentation-tier interface to reduce operational risk. The A2 audit identified that awkward phase transitions could silently reduce Q&A time if an instructor spoke between phases. In A3, we refined timer orchestration with Auto-Start Q&A on explicit transition to remove an extra click and reduce state ambiguity at the phase boundary. We also addressed the accessibility feedback by implementing a light theme option, improving legibility in bright classrooms—an example of a non-functional requirement (visibility) becoming a first-class design constraint.

We treated A3 as a shift from shipping an MVP to engineering a system that can be operated reliably. The CUJ framework did not just generate UI tweaks; it drove architectural choices about persistence guarantees, runtime initialization, and what API boundaries should mean in a cloud-deployed environment. Week 2 feedback provided the prioritization lens: optimize the instructor loop, reduce cognitive load, and make the system resilient to real classroom pacing.